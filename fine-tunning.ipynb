{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "\n",
    "This post provides an introduction to fine-tunning techniques that are taught in the Machine Learning subject of the intensive course in computing of the UAB's Bachelor's Degree in Computer Engineering. In it, we will learn how to fine-tune a **Convolutional Neural Network (CNN)** for a vision-related classification task. The code for this blog post can be found [here](https://github.com/dvd42/fine-tunning-with-pytorch)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Fine-Tunning\n",
    "\n",
    "In Deep Learning fine-tunning refers to the practice of taking the parameters of a **pre-trained** neural network (usually a **CNN**) and change them slightly. Training the network to generalize on a different dataset from that which it was trained on.\n",
    "\n",
    "### 2.1 Why do we use fine-tunning?\n",
    "\n",
    "1. Convolutional Networks usually have a large number of parameters, often in the range of **millions**. Training one of these CNNs with a dataset that is significantly smaller than the number of parameters it has, will prevent it from generalizing, making it **overfit** the data.\n",
    "\n",
    "2. Training a Network with millions of parameters from scratch takes a large amount of time.  \n",
    "\n",
    "Fine-tunning bypass **both** of these problems by taking an already trained network, modifying it slightly and **re-train it on new data**. Avoiding overfitting and making the training significantly faster.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 How to fine-tune?\n",
    "\n",
    "\n",
    "The first thing you have to do is change only the last fully-connected layer of the network, replacing with your own layer with your own, having as many output units as your task requires. For example: A network trained with **Imagenet** will have **1000 neurons** on the last layer, since Imagenet has 1000 classes. If our dataset has only **10 classes** we just replace the last layer with one that has **10 neurons**.\n",
    "\n",
    "Once this is done Fine-tunning can be performed in mainly in 3 different ways:\n",
    "\n",
    "1. **Freeze the entire network** and train only the **newly added layer** with a normal learning rate. \n",
    "\n",
    "\n",
    "2. **Freeze the first layers** of the network **(no backprop)** and train the rest of the network with a **smaller learning rate**. Since the first convolutional layers always **focus on edges and corners** it is very likely that we don't have to change their weights because no matter what your image has in it, it will always have corners and edges. The **newyly added layer** should be trained with a normal learning rate.  \n",
    "\n",
    "\n",
    "3. Re-train the **entire network** with high learning rate. The previous approaches cna work when the domain of the new task is **similar** to the one with which the network was pre-trained. But when the domain of the new task **differs** a lot from the original one, the network must **re-learn a lot**, and so **more agressive** parameter updates are required.\n",
    "\n",
    "\n",
    "\n",
    "![weights](fine-tunning_images/weights.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Dependencies\n",
    "\n",
    "For this task we will use the following libraries: \n",
    "   \n",
    "   * Numpy: For matrix and vector operations\n",
    "   * Pytorch: Train and validate our neural network using parallel GPU computation\n",
    "   * Matplotlib: To visualize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import SGD\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as T\n",
    "from torchvision import models, datasets\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Dataset\n",
    "\n",
    "The Dataset that we will use for this blog is the one used at the ISIC lesion diagnosis challenge. The lesion images come from the HAM10000 Dataset, and were acquired with a variety of dermatoscope types, from all anatomic sites (excluding mucosa and nails), from a historical sample of patients presented for skin cancer screening, from several different institutions. \n",
    "\n",
    "The distribution of disease states represent a modified “real world” setting whereby there are more benign lesions than malignant lesions, but an over-representation of malignancies.  \n",
    "The Dataset consists of 10015 images belonging to one of 6 of the following classes.\n",
    "\n",
    "![data](fine-tunning_images/data.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Preparing Data\n",
    "\n",
    "For this task we will use a **Resnet18** network architecture trained on **Imagenet**.  \n",
    "\n",
    "![resnet18](fine-tunning_images/resnet18.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First thing we have to do is download the pre-trained model using PyTorch\n",
    "model = models.resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Data augmentation\n",
    "\n",
    "For this dataset we can use some data augmentation techniques. A very common practice is to Randomly flip an image horizontally. Since no information is lost by performing this operation, we can effectively augment the amount of images in our dataset.  \n",
    "On top of that you can also crop a random section of the image and feed that to the network, this is also a good technique to effectively augment the amount of images in the dataset while also helping the network to generalize better since it adds more variance to the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Data Normalization\n",
    "\n",
    "The network must be used with 224x244 images. Also the images with which the network was trained were normalized using the Imagenet mean and standard deviation. We will adapt our data keeping these 2 things in mind.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation and normalization\n",
    "train_trans = T.Compose([T.RandomResizedCrop(224), T.RandomHorizontalFlip(), T.ToTensor(),\n",
    "                                  T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "\n",
    "val_trans = T.Compose([T.Resize(224),T.CenterCrop(224), T.ToTensor(),\n",
    "                       T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training and validation datasets\n",
    "train_set = datasets.ImageFolder(\"/home/diego/DATASETS/ISIC_Challenge/train\", train_trans)\n",
    "val_set = datasets.ImageFolder(\"/home/diego/DATASETS/ISIC_Challenge/val\", val_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish hyper-parameters\n",
    "batch_size = 256\n",
    "lr = 0.05\n",
    "n_gpus = 2\n",
    "momentum = 0.9\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our dataloaders\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=8)\n",
    "val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data is now ready to be fed into the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Modify the model\n",
    "\n",
    "As mentioned above the network must be modified slightly before the fine-tunning process. Since the **domain** of the **data** is **quite different** from the one in which the network was trained we will use approach **3**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify last layer\n",
    "in_features = model.fc.in_features \n",
    "model.fc = nn.Linear(in_features, 7) # we have 7 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.cuda() # move model to GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Multiple GPUs\n",
    "\n",
    "Some models are too big for even the most powerful GPUs in the market, that's why it is necessary to train some models on more than one GPU in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model on all gpus\n",
    "model = nn.DataParallel(model, list(range(n_gpus))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Training and Validation\n",
    "Now we can start the training and validation of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Create optimizer for the network parameters\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "torch.backends.cudnn.benchmark = True # choose the optimal convolution algorithm\n",
    "\n",
    "def train():\n",
    "    \n",
    "    model.train() # set model to training mode\n",
    "    \n",
    "    running_loss = 0\n",
    "    running_corrects = 0\n",
    "    total = 0\n",
    "\n",
    "    for data, labels in train_loader:\n",
    "        \n",
    "        optimizer.zero_grad()  # make the gradients 0\n",
    "        \n",
    "        x = data.cuda()\n",
    "        y = labels.cuda()\n",
    "        \n",
    "        output = model(x)  # forward pass\n",
    "        loss = criterion(output, y)  # calculate the loss value\n",
    "        preds = output.max(1)[1] # get the predictions for each sample\n",
    "\n",
    "\n",
    "        loss.backward() # compute the gradients\n",
    "        optimizer.step() # uptade network parameters\n",
    "\n",
    "        # statistics\n",
    "        running_loss += loss.item() * x.size(0)\n",
    "        # .item() converts type from torch to python float or int\n",
    "        running_corrects += torch.sum(preds == y).item()\n",
    "        total += float(y.size(0))\n",
    "\n",
    "    epoch_loss = running_loss / total  # mean epoch loss\n",
    "    epoch_acc = running_corrects / total  # mean epoch accuracy\n",
    "\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "\n",
    "def val():\n",
    "\n",
    "    model.eval()  # set model to validation mode\n",
    "\n",
    "    running_loss = 0\n",
    "    running_corrects = 0\n",
    "    total = 0\n",
    "    \n",
    "    # We are not backpropagating through the validation set, so we can save time  and memory \n",
    "    # by not computing the gradients\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for data, labels in val_loader:\n",
    "            \n",
    "            x = data.cuda()\n",
    "            y = labels.cuda()\n",
    "        \n",
    "            output = model(x)  # forward pass \n",
    "            \n",
    "            # Calculate the loss value (we do not to apply softmax to our output because Pytorch's \n",
    "            # implementation of the cross entropy loss does it for us)\n",
    "            loss = criterion(output, y) \n",
    "            preds = output.max(1)[1] # get the predictions for each sample\n",
    "            \n",
    "            # Statistics\n",
    "            running_loss += loss.item() * x.size(0)\n",
    "            # .item() converts type from torch to python float or int\n",
    "            running_corrects += torch.sum(preds==y).item()\n",
    "            total += float(y.size(0))\n",
    "    \n",
    "    epoch_loss = running_loss / total # mean epoch loss\n",
    "    epoch_acc = running_corrects / total # mean epoch accuracy\n",
    "    \n",
    "    return epoch_loss, epoch_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Remove this line out of jupyter notebooks\n",
    "from IPython import display\n",
    "\n",
    "train_accuracy = []\n",
    "val_accuracy = []\n",
    "train_loss = []\n",
    "val_loss = []\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    loss, acc = train()\n",
    "    train_loss.append(loss)\n",
    "    train_accuracy.append(acc)\n",
    "    \n",
    "    loss, acc = val()\n",
    "    val_loss.append(loss)\n",
    "    val_accuracy.append(acc)\n",
    "    \n",
    "    plt.subplot(1,2,1)\n",
    "    plt.title(\"loss\")\n",
    "    plt.plot(train_loss, 'b-')\n",
    "    plt.plot(val_loss, 'r-')\n",
    "    plt.legend([\"train\", \"val\"])\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.title(\"accuracy\")\n",
    "    plt.plot(train_accuracy, 'b-')\n",
    "    plt.plot(val_accuracy, 'r-')\n",
    "    plt.legend([\"train\", \"val\"])\n",
    "    display.clear_output(wait=True)\n",
    "    display.display(plt.gcf())\n",
    "display.clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7945137157107232\n"
     ]
    }
   ],
   "source": [
    "print(max(val_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Conclusions\n",
    "\n",
    "On this blog post we learned how to use PyTorch to fine-tune a Convolutional Neural Network using multiple GPUs and data augmentation and normalization techniques.  \n",
    "We obtain a $79.4\\%$ accuracy score. Of course this model can be optimized much more by tinkering with the hyper-parameters a little, by using a [learning rate scheduler](https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate) and in many other ways.  \n",
    "Feel free to download this [notebook](https://github.com/dvd42/fine-tunning-with-pytorch) and experiment with various configurations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
